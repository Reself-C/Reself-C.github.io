---
layout: post
title: "CVPR 2022 | in-person Record"
author: "Reself"
categories: arXiv
tags: [conference]
image: cvpr/logo.png
---

因为身在美国，笔者这次将会在新奥尔良现场直击CVPR2022。由于论文众多，在会前把需要把所有文章大致扫一遍，并且在会后补充了记录，以下按时间顺序列出了觉得需要follow的一些solid work。以下是目录:

---

- [Introduction](#introduction)
- [Workshop](#workshop)
  - [Machine Learning with Synthetic Data (SyntML) link](#machine-learning-with-synthetic-data-syntml-link)
  - [International Challenge on Activity Recognition (ActivityNet) link](#international-challenge-on-activity-recognition-activitynet-link)
  - [2nd Workshop and Challenge on Computer Vision in the Built Environment for the Design, Construction, and Operation of Buildings link](#2nd-workshop-and-challenge-on-computer-vision-in-the-built-environment-for-the-design-construction-and-operation-of-buildings-link)
  - [Workshop on Attention and Transformers in Vision link](#workshop-on-attention-and-transformers-in-vision-link)
  - [5th MUltimodal Learning and Applications Workshop (MULA) link](#5th-multimodal-learning-and-applications-workshop-mula-link)
  - [O-DRUM: Workshop on Open-Domain Retrieval Under a Multi-Modal Setting link](#o-drum-workshop-on-open-domain-retrieval-under-a-multi-modal-setting-link)
  - [3rd International Workshop on Large Scale Holistic Video Understanding link](#3rd-international-workshop-on-large-scale-holistic-video-understanding-link)
  - [International Challenge on Activity Recognition (ActivityNet) link](#international-challenge-on-activity-recognition-activitynet-link-1)
  - [7th BMTT Workshop on Benchmarking Multi-Target Tracking: How Far Can Synthetic Data Take us? link](#7th-bmtt-workshop-on-benchmarking-multi-target-tracking-how-far-can-synthetic-data-take-us-link)
  - [L3D-IVU: Workshop on Learning with Limited Labelled Data for Image and Video Understanding link](#l3d-ivu-workshop-on-learning-with-limited-labelled-data-for-image-and-video-understanding-link)
- [Tutorial](#tutorial)
  - [Denoising Diffusion-based Generative Modeling: Foundations and Applications link](#denoising-diffusion-based-generative-modeling-foundations-and-applications-link)
  - [Recent Advances in Vision-and-Language Pre-training link](#recent-advances-in-vision-and-language-pre-training-link)
  - [Multimodal Machine Learning link](#multimodal-machine-learning-link)
  - [Evaluating Models Beyond the Textbook: Out-of-distribution and Without Labels link](#evaluating-models-beyond-the-textbook-out-of-distribution-and-without-labels-link)
  - [Creating and Using Synthetic Data for Computer Vision Applications - Rendered.ai link](#creating-and-using-synthetic-data-for-computer-vision-applications---renderedai-link)

---

## Introduction

国际计算机视觉与模式识别会议（CVPR）是IEEE一年一度的学术性会议，会议的主要内容是计算机视觉与模式识别技术。CVPR是世界顶级的计算机视觉会议（三大顶会之一，另外两个是ICCV和ECCV）。今年在6月19日-24日，地点位于新奥尔良。笔者身为IEEE student member报名前去现场参会。

## Workshop

CVPR workshop June 19-20th.

[full schedule](https://cvpr2022.thecvf.com/workshop-schedule)


### Machine Learning with Synthetic Data (SyntML) [link](https://syntml-cvpr2022-workshop.github.io/)

Synthetic data are labeled data made using computer graphic. They are cheap, clean, and have richness of label. 
Keyword: *Domain mismatch*, *Diversity*

1. human synthesis *Google*
    - Procedural face generation\
       templete + features paradigm\
       features can be: identity, expression, pose
    - Hair and clothing
    - Environment
    - Render (Blender)

2. synthetic data & simulation *Nvudia*
    - graphics
        geometry + texture by a distribution
    - mixed reality
        *light* estimation + AR
    - generative models
        GAN / diffusion model

3. crossing the domain gap with synthetic data *Datagen*
    - why synthetic data?
      - pixel-accurate labels 
      - rich annotationns 
      - full control
    - types of gap
      - *photorealism gap*
      - pose gap
      - augmentation gap
      - annotation gap
    - styleGAN
      - cascade "parameter w class" (also like templete + features)
      - inversion / editing (good sensitivity)
    - mix sythetic data with real data (when limited) can achieve better performance
    - address domain gap
      - photorealism
      - label adaptation
      - add noise
      - global scene parameter distribution (lights, camera, pose)

### International Challenge on Activity Recognition (ActivityNet) [link](http://activity-net.org/challenges/2022/)

task: real-time online untrimmed security video action detection\
object: single / multi / interaction\
pipeline:
- detection
- background removal
- tracking (IOU-based)
- classification

related concept:
- domain adaptation
- overlapping spatio-temperal
- class-unbalance
- multi-label
- generalization performance

### 2nd Workshop and Challenge on Computer Vision in the Built Environment for the Design, Construction, and Operation of Buildings [link](https://cv4aec.github.io/)

- task: building model through point clouds to room map
- key tech: sementic segmentation of point clouds

### Workshop on Attention and Transformers in Vision [link](https://sites.google.com/view/t4v-cvpr22)

1. Visual Attention with Recurrency and Sparsity
2. BoxeR: Box-Attention for 2D and 3D Transformers
   - 2D / 3D object detection or segmentation
   - query: reference window
   - key: learnable relative region
   - multi-scale feature map
3. Depth Estimation with Simplified Transformers
   - FC -> 1x1 Conv.
4. M2F3D: MaskFormer fo 3D Instance Segmentation
   - top-down / bottom-up
   - sparse Conv.

### 5th MUltimodal Learning and Applications Workshop (MULA) [link](https://mula-workshop.github.io/)

### O-DRUM: Workshop on Open-Domain Retrieval Under a Multi-Modal Setting [link](https://asu-apg.github.io/odrum/)

### 3rd International Workshop on Large Scale Holistic Video Understanding [link](https://holistic-video-understanding.github.io/workshops/cvpr2022.html)

### International Challenge on Activity Recognition (ActivityNet) [link](http://activity-net.org/challenges/2022/)

### 7th BMTT Workshop on Benchmarking Multi-Target Tracking: How Far Can Synthetic Data Take us? [link](https://motchallenge.net/workshops/bmtt2022/)

### L3D-IVU: Workshop on Learning with Limited Labelled Data for Image and Video Understanding [link](https://sites.google.com/view/l3d-ivu/)

## Tutorial

CVPR tutorial June 19-20th.

### Denoising Diffusion-based Generative Modeling: Foundations and Applications [link](https://cvpr2022-tutorial-diffusion-models.github.io/)

- kinds of diffusion model
    - momentum-based
    - energy-based
    - latent-space (with pretrained VAE): faster  and simpler
    - distilation (merge steps)
    - discrete state diffusion model
- high-resolution
    - condition form: scalar / image / text
    - quality-diversity trade-off
    - cascade generation with super-resolution method
- application
    - sementic segmentation
    - image editing
    - adversarial robustness (purfied image)
    - video generation
      - types
        - all frames
        - past frames
        - future frames
        - interpolation
      - tips: training with different types of mask / use time position encodings to encode times
      - backbone: 3D Conv. / 2D Conv. + Att. (ignore initially when train)
      - long-term: generate a frame far away and interpolation
    - medical imaging\
        reconstract original image from sparse measurements\
        high-level idea: learn pretrained on pure dataset momdel as "prior" than guide synthesis conditioned on sparse obvervations
    - 3D shape generation\
        through point clouds
- future trend
    - why diffusion models perform better?
    - how can we improve VAE / flow from diffusion model?
    - sampling from diffusion model is still slow
    - diffusion model can be considered as latent variable model *without sementic*, if with?
    - can diffusion model help to discrimination applications?
    - what are the best network architectures for diffusion model instead of UNet?
    - other data modality further than 2D image
    - controllable generation
    - in some application replace GAN with diffusion model


### Recent Advances in Vision-and-Language Pre-training [link](https://vlp-tutorial.github.io/2022/)

- unifying text and image
- avoiding explicit detection module
- high resolution computing cost
- coarse to fine two-stage VLP
- fusion in the backbone

### Multimodal Machine Learning [link](https://cmu-multicomp-lab.github.io/mmml-tutorial/cvpr2022/)

### Evaluating Models Beyond the Textbook: Out-of-distribution and Without Labels [link](https://sites.google.com/view/evalmodel)

### Creating and Using Synthetic Data for Computer Vision Applications - Rendered.ai [link](https://rendered.ai/conferences/cvpr2022/)

Wenhao(Reself) Chai
Undergraduate, UIUC